---
title: "Regression Analysis I"
author: "Andrea Huerfano"
date: "August 19, 2019"
output:
  pdf_document: default
  html_document:
    df_print: paged
header-includes:
- \usepackage{float}
- \floatplacement{figure}{H}
---

```{r, message=FALSE, warning=FALSE}
library(GLMsData)
data(AIS)
library(dplyr)
AIS_f<-AIS%>%filter(Sex=='F')
```


This file is one of the regression analysis papers. Here you can find:

+ Plots
+ Correlations
+ Identifying the best model
+ Influence and leverage points
+ Residuals examination
+ Variance examination

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
######## Correlaciones de Pearson ###########################################################################################################
######## Calcula las correlaciones de Pearson para todo par de variables (incluyendo la respuesta) y realiza gr√°ficos de dispersi√≥n de cada
######## variable explicativa frente a la respuesta. Los par√°metros de la funci√≥n  Correlaciones(objeto,a,b,d,nombres) son:
######## 1. Objeto. Objeto de R donde est√°n guardados los resultados de la regresi√≥n
######## 2. a. N√∫mero de filas de gr√°ficos
######## 3. b. N√∫mero de columnas de gr√°ficos
######## 4. d. N√∫mero de observaciones que se quieren identificar en cada diagrama de dispersi√≥n.
######## 5. nombres. Nombre de la variable donde est√°n los nombres o etiquetas de las observaciones. Si no existe tal etiqueta o no se quiere
######## usar, se debe diligenciar este par√°metro como "".

Correlaciones <- function(objeto,a,b,d,nombres){
  y <- objeto$residuals + fitted(objeto)
  if(length(nombres)<length(y)){
    nombres <- seq(1,length(y),by=1)
  }
  X <- model.matrix(objeto)
  if(mean(X[,1])==1){
    p <- ncol(model.matrix(objeto))
    labels <- labels(coef(objeto))
    respuesta <- names(objeto$model[1])
    par(mfrow=c(a,b))
    for(i in 2:p){
      plot(X[,i], y, main=labels[i], xlab=labels[i], ylim=c(min(y),max(y)), ylab=respuesta, cex=0.3, lwd=3)
      abline(lm(y~1+X[,i]),0,lty=3)
      identify(X[,i], y, n=d, labels=nombres)
    }
    resultado <- cor(cbind(objeto$model))
  }
  
  if(mean(X[,1])!=1){
    p <- ncol(model.matrix(objeto))
    labels <- labels(coef(objeto))
    respuesta <- names(objeto$model[1])
    par(mfrow=c(a,b))
    for(i in 1:p){
      plot(X[,i], y, main=labels[i], xlab=labels[i], ylim=c(min(y),max(y)), ylab=respuesta, cex=0.3, lwd=3)
      abline(lm(y~1+X[,i]),0,lty=3)
      identify(X[,i], y, n=d, labels=nombres)
    }
    resultado <- cor(cbind(objeto$model))
  }
  resultado
}


######## Correlaciones Parciales ###########################################################################################################
######## Calcula las correlaciones Parciales para cada variable explicativa frente a la respuesta y realiza un gr√°fico de dispersi√≥n con los
######## resultados. Los par√°metros de la funci√≥n Correlaciones.parcial(objeto,a,b,d,nombres) son:
######## 1. Objeto. Objeto de R donde est√°n guardados los resultados de la regresi√≥n
######## 2. a. N√∫mero de filas de gr√°ficos
######## 3. b. N√∫mero de columnas de gr√°ficos
######## 4. d. N√∫mero de observaciones que se quieren identificar en cada diagrama de dispersi√≥n.
######## 5. nombres. Nombre de la variable donde est√°n los nombres o etiquetas de las observaciones. Si no existe tal etiqueta o no se quiere
######## usar, se debe diligenciar este par√°metro como "".

Correlaciones.parcial <- function(objeto,a,b,d,nombres){
  y <- objeto$residuals + fitted(objeto)
  if(length(nombres)<length(y)){
    nombres <- seq(1,length(y),by=1)
  }
  X <- model.matrix(objeto)
  if(mean(X[,1])==1){
    p <- ncol(model.matrix(objeto))
    labels <- labels(coef(objeto))
    respuesta <- names(objeto$model[1])
    resultado <- matrix(0,p-1,1)
    par(mfrow=c(a,b))
    for(i in 2:p){
      temporal1 <- glm(y ~ -1+X[,-i], family=gaussian())
      r1 <- y - fitted(temporal1)
      temporal2 <- glm(X[,i] ~ -1+X[,-i], family=gaussian())
      r2 <- X[,i] - fitted(temporal2)
      plot(r2, r1, main=labels[i], xlab=labels[i], ylab=respuesta, cex=0.3, lwd=3)
      abline(lm(r1~1+r2),0,lty=3)
      identify(r2, r1, n=d, labels=nombres)
      resultado[i-1] <- round(cor(r1,r2),3) 
    }
    resultado <- rbind(c("Variables","Respuesta"),cbind(labels[2:p],resultado))
  }
  
  if(mean(X[,1])!=1){
    p <- ncol(model.matrix(objeto))
    labels <- labels(coef(objeto))
    respuesta <- names(objeto$model[1])
    resultado <- matrix(0,p,1)
    par(mfrow=c(a,b))
    for(i in 1:p){
      temporal1 <- glm(y ~ 1+X[,-i], family=gaussian())
      r1 <- y - fitted(temporal1)
      temporal2 <- glm(X[,i] ~ 1+X[,-i], family=gaussian())
      r2 <- X[,i] - fitted(temporal2)
      plot(r2, r1, main=labels[i], xlab=labels[i], ylab=respuesta, cex=0.3, lwd=3)
      abline(lm(r1~1+r2),0,lty=3)
      identify(r2, r1, n=d, labels=nombres)
      resultado[i] <- round(cor(r1,r2),3) 
    }
    resultado <- rbind(c("Variables","Correlaci√≥n parcial con la respuesta"),cbind(labels[1:p],resultado))
  }
  resultado
}

######## Busqueda del "mejor" modelo ###########################################################################################################
######## Calcula las medidas de la calidad del ajuste SCRes, R2, R2 Ajustado y AIC para todas las combinaciones de modelos con i variables
######## explicativas. Los par√°metros de la funci√≥n ajuste.normal(objeto,i) son:
######## 1. Objeto. Objeto de R donde est√°n guardados los resultados de la regresi√≥n
######## 2. i. El n√∫mero de variables explicativas que se quieren en el modelo.

ajuste.normal <- function(objeto,i){
  y <- objeto$residuals + fitted(objeto)
  X <- model.matrix(objeto)
  p <- ncol(model.matrix(objeto))
  labels <- labels(coef(objeto))
  weights=objeto$weights
  if(length(weights)<length(y)){
    weights <- matrix(1,length(y),1)
  }
  if(mean(X[,1])==1){
    id <- seq(2,p,by=1)
    opcion <- t(combn(id,i))
    nn <- matrix(0,nrow(opcion),4)
    lab <- matrix(0,nrow(opcion),i+1)
    for(j in 1:nrow(opcion)){
      temp <- glm(y ~ 1+X[,opcion[j,]], family=gaussian(), weights=weights)
      mr <- (length(y)-1)*var(y)
      nn[j,4] <- round(AIC(temp),1)
      r2 <- (mr-sum((temp$y-fitted(temp))^2))/mr
      nn[j,3] <- round(1-(1-r2)*((length(y)-1)/(length(y)-1-i)),3)
      nn[j,1] <- round(sum((temp$y-fitted(temp))^2),1)
      nn[j,2] <- round(r2,3)
      lab[j,] <- labels[c(1,opcion[j,])]
    }
    lab2 <- matrix("",1,i+1)
    nn2 <- cbind("SCRes","R2","R2 Ajust","AIC")
    lab2[1] <- "Modelo"
    nn <- rbind(nn2,nn)
    lab <- rbind(lab2,lab)
    resultados <- cbind(lab,nn)
  }
  if(mean(X[,1])!=1){
    id <- seq(1,p,by=1)
    opcion <- t(combn(id,i))
    nn <- matrix(0,nrow(opcion),4)
    lab <- matrix(0,nrow(opcion),i)
    for(j in 1:nrow(opcion)){
      temp <- glm(y ~ -1+X[,opcion[j,]], family=gaussian(), weights=weights)
      mr <- sum(y*y)
      nn[j,4] <- round(AIC(temp),1)
      r2 <- (mr-sum((temp$y-fitted(temp))^2))/mr
      nn[j,3] <- round(1-(1-r2)*((length(y)-1)/(length(y)-1-i)),3)
      nn[j,1] <- round(sum((temp$y-fitted(temp))^2),1)
      nn[j,2] <- round(r2,3)   
      lab[j,] <- labels[opcion[j,]]
    }
    lab2 <- matrix("",1,i)
    nn2 <- cbind("SCRes","R2","R2 Ajust","AIC")
    lab2[1] <- "Modelo"
    nn <- rbind(nn2,nn)
    lab <- rbind(lab2,lab)
    resultados <- cbind(lab,nn)
  }
  resultados
}


######## Identificando puntos de alto Leverage ###################################################################################################################
######## Calcula los valores de la diagonal principal de la matriz de proyecci√≥n ortogonal H.
######## Los par√°metros de la funci√≥n Leverage.normal(objeto,d,nombres) son:
######## 1. Objeto. Objeto de R donde est√°n guardados los resultados de la regresi√≥n
######## 2. d. N√∫mero de observaciones que se quieren identificar.
######## 3. nombres. Nombre de la variable donde est√°n los nombres o etiquetas de las observaciones. Si no existe tal etiqueta o no se quiere
######## usar, se debe diligenciar este par√°metro como "".

Leverage.normal <- function(objeto,d,nombres){
  y <- objeto$residuals + fitted(objeto)
  if(length(nombres)<length(y)){
    nombres <- seq(1,length(y),by=1)
  }
  H <- matrix(0,length(y),1)
  X <- model.matrix(objeto)
  sigma2 <- sum(objeto$residuals^2)/(length(y)-ncol(X))
  XtX <- vcov(objeto)/sigma2
  for(i in 1:length(y)){
    H[i] <- t(X[i,])%*%XtX%*%X[i,]
  }
  maxy <- max(max(H),2*mean(H))
  plot(H, main="Puntos de alto Leverage", xlab="√çndice", ylim=c(0,maxy), ylab="h", cex=0.3, lwd=3)
  abline(2*mean(H),0,lty=3)
  identify(H, n=d,labels=nombres)
  H
}


######## Residuos Estandarizados ###############################################################################################################
######## Construye el gr√°fico de residuos est√°ndarizados del modelo. Los par√°metros de la funci√≥n Residuos.normal(objeto,d,nombres) son:
######## 1. Objeto. Objeto de R donde est√°n guardados los resultados de la regresi√≥n
######## 2. d. N√∫mero de observaciones que se quieren identificar.
######## 3. nombres. Nombre de la variable donde est√°n los nombres o etiquetas de las observaciones. Si no existe tal etiqueta o no se quiere
######## usar, se debe diligenciar este par√°metro como "".

Residuos.normal <- function(objeto,d,nombres){
  y <- objeto$residuals + fitted(objeto)
  h <- matrix(0,length(y),1)
  X <- model.matrix(objeto)
  sigma <- sum(objeto$residuals^2)/(length(y)-ncol(X))
  XtX <- vcov(objeto)/sigma
  for(i in 1:length(y)){
    h[i] <- t(X[i,])%*%XtX%*%X[i,]
  }
  r <- (y-fitted(objeto))/sqrt((1-h)*sigma)
  r <- r*sqrt((length(y)-ncol(X)-1)/(length(y)-ncol(X)-r*r))
  maxy <- max(max(r),3)
  miny <- min(min(r),-3)
  if(length(nombres)<length(y)){
    nombres <- seq(1,length(y),by=1)
  }
  plot(fitted(objeto), r, main="Observaciones extremas en la respuesta", xlab="Media estimada", ylab="Residuo estandarizado", cex=0.3, lwd=3, ylim=c(miny,maxy))
  abline(2,0,lty=3)
  abline(0,0,lty=3)
  abline(-2,0,lty=3)
  identify(x=fitted(objeto), y=r, n=d, labels=nombres)
  r
}



######## QQ Plot y sus bandas de confianza ###################################################################################################################
######## Construye el gr√°fico QQ plot junto con sus bandas de confianza. Los par√°metros de la funci√≥n qqplot.normal(objeto,k,alfa,d,nombres) son:
######## 1. Objeto. Objeto de R donde est√°n guardados los resultados de la regresi√≥n
######## 2. d. N√∫mero de r√©plicas para la simulaci√≥n.
######## 3. alpha. El nivel de confianza para las bandas del QQ plot es de 100*(1-alpha)%.
######## 4. d. N√∫mero de observaciones que se quieren identificar.
######## 5. nombres. Nombre de la variable donde est√°n los nombres o etiquetas de las observaciones. Si no existe tal etiqueta o no se quiere
######## usar, se debe diligenciar este par√°metro como "".

qqplot.normal <- function(objeto,k,alfa,d,nombres){
  y <- objeto$residuals + fitted(objeto)
  if(length(nombres)<length(y)){
    nombres <- seq(1,length(y),by=1)
  }
  y <- objeto$residuals + fitted(objeto)
  X <- model.matrix(objeto)
  n <- nrow(X)
  p <- ncol(X)
  phi <- sum(objeto$residuals*objeto$residuals)/(length(y)-length(coef(objeto)))
  XtX <- vcov(objeto)/phi
  h <- matrix(0,length(y),1)
  for(i in 1:length(y)){
    h[i] <- t(X[i,])%*%XtX%*%X[i,]
  }
  r <- (y-fitted(objeto))/sqrt((1-h)*phi)
  r <- r*sqrt((length(y)-ncol(X)-1)/(length(y)-ncol(X)-r*r))
  alfa1 <- ceiling(k*alfa)
  alfa2 <- ceiling(k*(1-alfa))
  epsilon <- matrix(0,n,k)
  e <- matrix(0,n,k)
  e1 <- numeric(n)
  e2 <- numeric(n)
  
  for(i in 1:k){
    resp <- fitted(objeto) + rnorm(n,mean=0,sd=1)*sqrt(phi) 
    fits <- glm(resp ~ X, family=gaussian())
    phis <- sum(fits$residuals*fits$residuals)/(length(y)-length(coef(fits)))
    rs <- (resp-fitted(fits))/sqrt((1-h)*phis)
    rs <- rs*sqrt((length(y)-ncol(X)-1)/(length(y)-ncol(X)-rs*rs))
    e[,i] <- sort(rs)
  }
  med <- apply(e,1,mean)
  
  for(i in 1:n){
    e0 <- sort(e[i,])
    e1[i] <- e0[alfa1]
    e2[i] <- e0[alfa2]
  }
  faixa <- range(r,e1,e2)
  par(pty="s")
  qqnorm(e1,axes=F,xlab="",type="l",ylab="",main="",ylim=faixa,lty=1)
  par(new=T)
  qqnorm(e2,axes=F,xlab="",type="l",ylab="",main="",ylim=faixa,lty=1)
  par(new=T)
  qqnorm(med,axes=F,xlab="",type="l",ylab="",main="",ylim=faixa,lty=3)
  par(new=T)
  dd <- qqnorm(r,xlab="Percentiles de la N(0,1)", ylab="Residuos",main="QQ Plot", ylim=faixa, cex=0.3, lwd=3)
  identify(dd$x,r,n=d, labels=nombres)
}


######## Influencia ###############################################################################################################
######## Construye gr√°ficos de la Distancia de Cook para cada uno de los par√°metros de localizaci√≥n en el modelo y un gr√°fico de la
######## Distancia de Cook para la influencia general sobre el vector B. Los par√°metros de la funci√≥n Influence.normal(objeto,a,b,d,nombres) son:
######## 1. Objeto. Objeto de R donde est√°n guardados los resultados de la regresi√≥n
######## 2. a. N√∫mero de filas de gr√°ficos
######## 3. b. N√∫mero de columnas de gr√°ficos
######## 4. d. N√∫mero de observaciones que se quieren identificar en cada gr√°fico.
######## 5. nombres. Nombre de la variable donde est√°n los nombres o etiquetas de las observaciones. Si no existe tal etiqueta o no se quiere
######## usar, se debe diligenciar este par√°metro como "".

Influence.normal <- function(objeto,a,b,d,nombres){
  y <- objeto$residuals + fitted(objeto)
  X <- model.matrix(objeto)
  if(length(nombres)<length(y)){
    nombres <- seq(1,length(y),by=1)}
  delta <- lm.influence(objeto)$coef
  DC <- diag(delta%*%solve(vcov(objeto))%*%t(delta))/ncol(X)
  maxy <- max(max(DC),3*mean(DC))
  plot(DC, main="Observaciones influyentes", xlab="√çndice", ylim=c(0,maxy), ylab="Distancia de Cook", cex=0.3, lwd=3)
  abline(3*mean(DC),0,lty=3)
  identify(DC, n=d, labels=nombres)
  p <- ncol(X)
  labels <- labels(coef(objeto))
  respuesta <- names(objeto$model[1])
  X11()
  par(mfrow=c(a,b))
  for(i in 1:p){
    a <- matrix(0,1,p)
    a[i] <- 1
    delta <- lm.influence(objeto)$coef[,i]
    DCi <- diag(delta%*%solve(a%*%vcov(objeto)%*%t(a))%*%t(delta))
    maxy <- max(max(DCi),3*mean(DCi))
    plot(DCi, main=labels[i], xlab="√çndice", ylim=c(0,maxy), ylab="Distancia de Cook", cex=0.3, lwd=3)
    abline(3*mean(DCi),0,lty=3)
    identify(DCi, n=d, labels=nombres)
  }
  DC
}

```


Physical measurements and blood measurements from high performance athletes at the AIS, this dataset contain information about 98 athletes and it is a subset of the data(AIS) in the library GLMsData. The function *summary* was used to obtain the following result
```{r, warning=FALSE}
library(readxl)
colnames(AIS_f)
atletas<-subset(AIS_f,select = c("LBM", "Ht", "Wt", "BMI", "SSF"))
```
The summary function is an excelent option to see a brief description of each variable, finding here all of the quantiles. 
```{r}
summary(atletas)
```

##Scatterplot matrix
Another good option is looking a matrix with all the scatterplots. For example we can see that Wt and BMI have a linear behavior with the response variable (LBM), and the other variables even when some of them have an aproximate linear behavior is easy to see that these ones are more dispersed, for example: Ht and SSF. 
```{r, warning=FALSE,message=FALSE,fig.height=5, fig.pos='h'}
library(GGally)
ggpairs(atletas, columns = 1:ncol(atletas), title = "",  
  axisLabels = "show", columnLabels = colnames(atletas))
```



##Correlations
The simple correlation is a measure used to determine the strength and the direction of the relationship between two variables. In this example the independent variable is lbm and the other ones are the dependent variables.


The scatterplots show  a strong lineal asociation between ht and lbm  that is reflected for a correlation of 0.7082, the second scatterplots shows a strong relation between wt and lbm that is respalded for a correlation of 0.9207. Between the BMI and lbm there is a correlation of 0.7474 which represent a strong relation as well. Another imporant fact is the strong relation reflected for a correlation of 0.847 between the BMI and wt, that means that some of the information in the variable BMI are in wt and viceversa, furthemore the correlation between wt and ht is really hight (0.7087).

```{r, results=FALSE}
fit <- lm(LBM ~ 1+Ht+Wt+BMI+SSF, data=atletas) ##This model contain all of the variables
##It is used to determine the simple and partial correlations
```

,
```{r,fig.height=7, fig.pos='h',echo=FALSE}
Correlaciones(fit,4,1,4,"") ##Choosing 3 points. So useful to determine outliers
```

##Partial correlation
The partial correlation for ht and lbm is shorter than the obtained in the plot of simple correlation, that means that part of the information of the ht varaible over the response variable is also conteined in the other dependent variables . The same result appears when the simple correlation coeficient is compared 0.7082 with 0.377. This situations occurs in the same way with Wt having 0.9207 vs 0.338. Finally, rcc has a partial correlation coefficient of 0.195. This correlations describe the information that has every variable and there is not conteined in ahother one.

```{r, fig.height=7,fig.pos='h'}
Correlaciones.parcial(fit,4,1,1,"")
```

```{r,, warning=FALSE, message=FALSE}
library(MASS)
library(zoo)
library(lmtest)
```


##Possible models


Models with one, two and 3 parameters are examined using the quality mesures: SCRes, R2, R2 ajust and AIC. Maximum R2 and Shorter AIC
```{r}
ajuste.normal(fit,1)
ajuste.normal(fit,2)
ajuste.normal(fit,3)
ajuste.normal(fit,4)
```
Over this results the best model will be that which contain all of the variables, however the model which contains just Wt and BMI has almost the same R2, furthemore, notice that the variable SSF seems with non homogenize variance, after running some models the best results were obtained appling log over there. 
```{r}
fit <- lm(LBM ~ 1+Wt+log(SSF), data=atletas)
summary(fit)
AIC(fit)
```


Now,see this model without intercept
```{r}
fit2 <- lm(LBM ~ -1+Wt+log(SSF), data=atletas)
summary(fit2)
AIC(fit2)

```
The R2 definition changes depends on the presence/ausence of the intercept, for that reason the R2 ajus there are not comparable between the two final that difers in intercept. To decide about the best model the AIC help us, we can see that the model I has shorter AIC than the model II, furthemore all of these parameter are significants, that is the reason to choose this model over the first one.


##Residuals examination
It is necessary to examine the residuals distribution, points of leverage and influence.

```{r, echo=FALSE, fig.height=6,fig.pos='h'}
######## Leverage #####################################

#par(mfrow=c(6,1))
Leverage <- Leverage.normal(fit,3,"")

######## Residuos #####################################
residuos <- Residuos.normal(fit,3,"")

######## Influencia #####################################
influence <- Influence.normal(fit,2,2,3,"")

######## QQ Plot y sus bandas de confianza ########
qqplot.normal(fit,500,0.01,3,"")

```
Well, the points 56,71 and 76 are the outliers, it is necessary talking with the expert to decide if it is necessary removing this points of the sample.

### Variance examination

```{r}
######## Evaluando homogeneidad de la varianza ########
library(lmtest)
######## Test de Breusch-pagan ########
bptest(fit)

```
 The Breusch-pagan's  test to examine the homogenicity in the variance is not rejected with a significant level of 5% 
```{r}
######## Evaluando NO correlaci√≥n de los errores ########
######## Test de Durbin-Watson ########

dwtest(fit)
```
 The autocorrelation between residuals is rejected at significant level of 5%
 
### Removing outliers

For this example, we are going to suppose that the best option is deleting the outliers 11 and 56 of out sample. Let see how the model behaviour witout this points.
```{r}
atletas2<-atletas[-c(11,56),]
```



```{r}
fit3<- lm(LBM ~ 1+Wt+log(SSF), data=atletas2)
summary(fit3)
AIC(fit3)
```
Well, the model seems good. Let's go to see the residuals examination
```{r,  fig.height=5,fig.pos='h'}
######## Leverage #####################################

#par(mfrow=c(6,1))
Leverage <- Leverage.normal(fit3,3,"")

######## Residuos #####################################
residuos <- Residuos.normal(fit3,3,"")

######## Influencia #####################################
influence <- Influence.normal(fit3,2,2,3,"")

######## QQ Plot y sus bandas de confianza ########
qqplot.normal(fit3,500,0.01,3,"")

```


```{r}
######## Evaluando homogeneidad de la varianza ########
library(lmtest)
######## Test de Breusch-pagan ########
bptest(fit3)

######## Evaluando NO correlaci√≥n de los errores ########
######## Test de Durbin-Watson ########

dwtest(fit3)

```
We can see that the model fits good the data and the residuals examination were good. Then our model is finished.

##Moldel interpretation
The final model is: $LBM=B_0+B_1Wt+B_2log(SSF)$, now, it is the time to interpretate its parameters. From the summary function we can identify just the coefficients.
```{r}
summary(fit3)$coef
```
+ $B_0$ for a person who has 0 in Wt and log(SSF) the LBM should be in average 36.6887 
+ $B_1$ for each adicional unit of the Wt the LBM should increase in average 0.8379 units
+ $B_2$ for each adicional unit of log(SSF) the LBM should decrease in average -8.68087 units


##References
```{r, echo=FALSE, results=FALSE}
citation("GLMsData")
citation("dplyr")
citation("readxl")
citation("GGally")
citation("MASS")
citation("zoo")
citation("lmtest")
```
 * Peter K. Dunn and Gordon K. Smyth (2018). GLMsData:
  Generalized Linear Model Data Sets. R package version 1.0.0.
  https://CRAN.R-project.org/package=GLMsData

* Hadley Wickham, Romain FranÁois, Lionel Henry and Kirill
  M¸ller (2019). dplyr: A Grammar of Data Manipulation. R
  package version 0.8.3.
  https://CRAN.R-project.org/package=dplyr
  
*  Hadley Wickham and Jennifer Bryan (2019). readxl: Read Excel
  Files. R package version 1.3.1.
  https://CRAN.R-project.org/package=readxl
  
*   Barret Schloerke, Jason Crowley, Di Cook, Francois Briatte,
  Moritz Marbach, Edwin Thoen, Amos Elberg and Joseph
  Larmarange (2018). GGally: Extension to 'ggplot2'. R package
  version 1.4.0. https://CRAN.R-project.org/package=GGally
  
*   Venables, W. N. & Ripley, B. D. (2002) Modern Applied
  Statistics with S. Fourth Edition. Springer, New York. ISBN
  0-387-95457-0

*   Achim Zeileis and Gabor Grothendieck (2005). zoo: S3
  Infrastructure for Regular and Irregular Time Series. Journal
  of Statistical Software, 14(6), 1-27.
  doi:10.18637/jss.v014.i06
  
*   Achim Zeileis, Torsten Hothorn (2002). Diagnostic Checking in
  Regression Relationships. R News 2(3), 7-10. URL
  https://CRAN.R-project.org/doc/Rnews/


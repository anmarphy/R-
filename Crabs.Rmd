---
title: "Crabs"
author: "Andrea Huerfano"
date: "September 4, 2019"
output: pdf_document
---
The function summary will be used to have a first idea of the data structure. 
```{r}
library(MASS)
library(dplyr)
library(ggplot2)
library(readr)
data(crabs)
colnames(crabs)
crabs<-crabs[,-3]
summary(crabs)

```
In the data set we have two category variables: sp and sex, the others are quantitatives, that is the reason why in sex appears barplots and the other variables have density distribution plots and scatter plots. The two colors are associeted with  the break up of sp wich has two levels.  

```{r, warning=FALSE,message=FALSE,fig.height=5, fig.pos='h'}
library(GGally)
ggpairs(crabs, columns = 2:ncol(crabs), title = "",  
  axisLabels = "show", mapping = aes(colour=sp))
```


For this model the first step is preparing the split to create two sets from the original dataset: training and testing sets, in this case we are going to use 80 percent of the sample for training the model and the other 20 percent will be used to validate de model's quality. The distribution of the observation in the two set is made over a random simple sampling applied over the index.
```{r}
# Random sample indexes
train_index <- sample(1:nrow(crabs), 0.8 * nrow(crabs))
test_index <- setdiff(1:nrow(crabs), train_index)

# Build X_train
X_train <- crabs[train_index,]
X_test <- crabs[test_index,]

```
#Correlation
We can see that the variables have a strong correlation almost all of them, that is a problem if I would try to put in the model all of these variables. The just the varaibles sex,FL,RW and CL will keep to start the model. 
```{r}
cor(X_train[,3:ncol(crabs)])
```


For the model selection we are going to use the Step aic and the R function glm will be used to compute de logistic regression, specifying the option family = binomial, that means the response variable is binary. AIC penalizes increasing the number of parameters into de model, and the best option will be the model with the smallest. Not all the variables are in the inicial model because of the high correlation between them as I said before.
```{r}
fit <- glm(sp ~ 1 + sex+FL+RW+CL+sex*FL+sex*RW, family=binomial, data=X_train)
stepAIC(fit)

```
Well, let see the best model in detail:

```{r}
fit<-glm(formula = sp ~ sex + FL + CL, family = binomial, data = X_train)
summary(fit)
```

We would like to know the probability that the event occurs when we have a male, with FL=11.1 and CL=23.8.

```{r}
###################### EstimaciÃ³n de una probabilidad ###################
x <- c(1,1,11.1,23.8)
eta <- sum(x*coef(fit))
prob <- exp(eta)/(1+exp(eta))
prob 

```
Now, using the function predict
```{r}
newdata <- data.frame( sex='M',FL=11.1,RW=9.9,CL=23.8,CW=27.1,BD=9.8)
probabilities <- fit %>% predict(newdata, type = "response")
probabilities
```
To predict the value in the testing set the threshold will be 0.4, that means that if the probability is greater than 0.4 the observation will be associated with   O and in another case will be mark with B.
```{r}
rev<-predict(fit,X_test,type = "response")
 X_test$predicted.classes<- ifelse(rev > 0.4, "O", "B")
head(X_test)
```

To check the model accuracy we are going to see the percent associated with values that were classified right.
```{r}
# Model accuracy
mean(X_test$predicted.classes == X_test$sp)
```

Finally to check the well know s-shape for the logistic regreesion we are going to use the ggplot library
```{r}
library(ggplot2)
X_test$rev<-predict(fit,X_test,type = "response")


X_test %>%
  ggplot(aes(CL, rev)) +
  geom_point(alpha = 0.1) +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  labs(
    title = "Logistic Regression Model", 
    x = "Plasma Glucose Concentration",
    y = "Probability of being diabete-pos"
    )
```
#Pseudo R2
McFadden measure is 0.88 that is a really good value because this metric ranges from 0 to just under 1, with values closer to zero indicating that the model has no predictive power. 
```{r}
library(pscl)
pR2(fit)
```


Finally, we exmaine the ROC curve which shows the trade off between the rate at which you can correctly predict something with the rate of incorrectly predicting something. 
```{r, fig.height=5}
library(ROCR)
# Compute AUC for predicting Class with the model
prob <- predict(fit, newdata=X_test, type="response")
pred <- prediction(prob, X_test$sp)
perf <- performance(pred, measure = "tpr", x.measure = "fpr")
plot(perf)
```

#Cross validation
